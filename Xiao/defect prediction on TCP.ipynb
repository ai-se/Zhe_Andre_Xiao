{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"parsl@parsl.csv\")\n",
    "data = data.to_numpy()\n",
    "\n",
    "data_process = pd.read_csv(\"process_parsl.csv\")\n",
    "data_process = data_process.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove non-test build\n",
    "print(len(data))\n",
    "test_build_data = []\n",
    "\n",
    "for row in data:\n",
    "    if row[9] == True:\n",
    "        test_build_data.append(row)\n",
    "\n",
    "print(len(test_build_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine same build\n",
    "unique_build = []\n",
    "\n",
    "prev_build = test_build_data[0][0]\n",
    "prev_commit = test_build_data[0][3]\n",
    "test_string = str(test_build_data[0][18])\n",
    "\n",
    "for i in range(1, len(test_build_data)+1):\n",
    "    if i == len(test_build_data):\n",
    "        unique_build.append([prev_build, prev_commit, test_string])\n",
    "        break\n",
    "    \n",
    "    if test_build_data[i][0] == prev_build:\n",
    "        test_string = test_string + \"#\" + str(test_build_data[i][18])\n",
    "    else:\n",
    "        unique_build.append([prev_build, prev_commit, test_string])\n",
    "        prev_build = test_build_data[i][0]\n",
    "        prev_commit = test_build_data[i][3]\n",
    "        test_string = str(test_build_data[i][18])\n",
    "\n",
    "# clear same tests\n",
    "for i in range(len(unique_build)):\n",
    "    temp_tests = []\n",
    "    \n",
    "    for item in unique_build[i][2].split(\"#\"):\n",
    "        if item !=\"nan\":\n",
    "            if item not in temp_tests:\n",
    "                temp_tests.append(item)\n",
    "    \n",
    "    write_tests = \"\"\n",
    "    for t in temp_tests:\n",
    "        if write_tests == \"\":\n",
    "            write_tests = write_tests + t\n",
    "        else:\n",
    "            write_tests = write_tests + \"#\" + t\n",
    "        \n",
    "    unique_build[i][2] = write_tests\n",
    "\n",
    "print(unique_build)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine two data set to [build ID, commit, file_change, tests] - Commit Guru + Travis CI\n",
    "combined_data = []\n",
    "\n",
    "count_overlap = 0\n",
    "count_no_overlap = 0\n",
    "for i in range(len(unique_build)):\n",
    "    findSame = False\n",
    "    \n",
    "    for j in range(len(data_process)):\n",
    "        if unique_build[i][1] == data_process[j][0]:\n",
    "            findSame = True\n",
    "            new_row = [unique_build[i][0], unique_build[i][1], data_process[j][17], unique_build[i][2]]\n",
    "            combined_data.append(new_row)\n",
    "            break\n",
    "    \n",
    "    if findSame:\n",
    "        count_overlap += 1\n",
    "    else:\n",
    "        count_no_overlap += 1\n",
    "\n",
    "print(\"overlap: \" + str(count_overlap) + \" \" + str(count_overlap/len(unique_build)))\n",
    "print(\"non-overlap: \" + str(count_no_overlap) + \" \" + str(count_no_overlap/len(unique_build)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrap file data from Github\n",
    "import csv\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import random\n",
    "import time\n",
    "\n",
    "with open(\"parsl_combined.csv\", \"w\", newline='', encoding=\"utf-8\") as f:\n",
    "    csv_writer = csv.writer(f, delimiter=',')\n",
    "    csv_writer.writerow(['build ID', 'commit', 'time', 'file change', 'tests'])\n",
    "    \n",
    "    for row in unique_build:\n",
    "        build_id = row[0]\n",
    "        commit_id = row[1]\n",
    "        test_info = row[2]\n",
    "        \n",
    "        url = \"https://github.com/Parsl/parsl/commit/\" + commit_id\n",
    "        print(url)\n",
    "        \n",
    "        r = requests.get(url)\n",
    "        soup = bs(r.content, \"html.parser\")\n",
    "        \n",
    "        myDiv = soup.findAll('div', {'class': 'file-info flex-auto min-width-0 mb-md-0 mb-2'})\n",
    "        \n",
    "        temp_file_list = []\n",
    "        for div in myDiv:\n",
    "            temp_file_list.append(div.find('a').text)\n",
    "            \n",
    "        timeDiv = soup.find('relative-time')\n",
    "        if timeDiv is not None:\n",
    "            commit_time = timeDiv.get('datetime')\n",
    "            print(commit_time)\n",
    "        else:\n",
    "            commit_time = \"\"\n",
    "        \n",
    "        output_file_string = \"\"\n",
    "        for f in temp_file_list:\n",
    "            if output_file_string == \"\":\n",
    "                output_file_string = output_file_string + f\n",
    "            else:\n",
    "                output_file_string = output_file_string + \"#\" + f\n",
    "        print(output_file_string)\n",
    "        \n",
    "        csv_writer.writerow([build_id, commit_id, commit_time, output_file_string, test_info])\n",
    "        \n",
    "        rand_int = random.randint(1, 4)\n",
    "        time.sleep(rand_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = pd.read_csv(\"parsl_combined.csv\")\n",
    "combined_data = combined_data.to_numpy()\n",
    "\n",
    "failed_data = []\n",
    "for row in combined_data:\n",
    "    if str(row[4]) != \"nan\":\n",
    "        failed_data.append(row)\n",
    "\n",
    "print(len(combined_data))\n",
    "print(len(failed_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "tot_len = len(failed_data)\n",
    "testing_len = int(tot_len * 0.7)\n",
    "testing_data = failed_data[testing_len:]\n",
    "print(testing_len)\n",
    "\n",
    "split_build_id = failed_data[testing_len][0]\n",
    "\n",
    "training_data = []\n",
    "\n",
    "for row in combined_data:\n",
    "    if row[0] == split_build_id:\n",
    "        break\n",
    "    \n",
    "    training_data.append(row)\n",
    "\n",
    "print(len(training_data))\n",
    "print(len(testing_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create File-Commit-Timestep Table\n",
    "file_list = []\n",
    "for row in training_data:\n",
    "    temp_file = row[3]\n",
    "    \n",
    "    for f in temp_file.split(\"#\"):\n",
    "        if f not in file_list:\n",
    "            file_list.append(f)\n",
    "\n",
    "file_commit_table = []\n",
    "\n",
    "for row in training_data:\n",
    "    cur_list = []\n",
    "    cur_list.append(row[1])\n",
    "    \n",
    "    for file in file_list:\n",
    "        if file in row[3].split('#'):\n",
    "            cur_list.append(1)\n",
    "        else:\n",
    "            cur_list.append(0)\n",
    "    \n",
    "    cur_list.append(row[2])\n",
    "    \n",
    "    file_commit_table.append(cur_list)\n",
    "\n",
    "print(file_commit_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect test cases, build test-file Table\n",
    "test_list = []\n",
    "for row in failed_data:\n",
    "    temp_test = row[4]\n",
    "    \n",
    "    for t in temp_test.split(\"#\"):\n",
    "        if t not in test_list:\n",
    "            test_list.append(t)\n",
    "\n",
    "test_file_table = [[0 for i in range(len(test_list))] for j in range(len(file_list))]\n",
    "for row in training_data:\n",
    "    if str(row[4]) != \"nan\":\n",
    "        for i in range(len(file_list)):\n",
    "            if file_list[i] in row[3].split(\"#\"):\n",
    "                for j in range(len(test_list)):\n",
    "                    if test_list[j] in row[4].split(\"#\"):\n",
    "                        test_file_table[i][j] += 1\n",
    "\n",
    "print(test_file_table)           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# timestamp for each commit\n",
    "import datetime\n",
    "\n",
    "list_timestamp = []\n",
    "list_commit = []\n",
    "for row in file_commit_table:\n",
    "    list_timestamp.append(row[-1])\n",
    "    list_commit.append(row[1])\n",
    "\n",
    "original_date = datetime.datetime(int(list_timestamp[0][0:4]), int(list_timestamp[0][5:7]), int(list_timestamp[0][8:10]), \n",
    "                                  int(list_timestamp[0][11:13]), int(list_timestamp[0][14:16]), int(list_timestamp[0][17:19]))\n",
    "\n",
    "norm_timestamp = []\n",
    "for item in list_timestamp:\n",
    "    temp_date = datetime.datetime(int(item[0:4]), int(item[5:7]), int(item[8:10]),\n",
    "                                  int(item[11:13]), int(item[14:16]), int(item[17:19]))\n",
    "    \n",
    "    diff = temp_date - original_date\n",
    "    diff_sec = diff.total_seconds()\n",
    "    score = diff_sec * 1\n",
    "    norm_timestamp.append(score+5)\n",
    "\n",
    "file_score = {}\n",
    "for f in file_list:\n",
    "    file_score.update({f: 0})\n",
    "\n",
    "for i in range(len(training_data)):\n",
    "    tc = norm_timestamp[i]/max(norm_timestamp)\n",
    "    \n",
    "    for f in training_data[i][3].split(\"#\"):\n",
    "        file_score[f] += tc\n",
    "\n",
    "for key in file_score:\n",
    "    print(key + \": \" + str(file_score[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.4 64-bit",
   "language": "python",
   "name": "python36464bit9a12fa083eaa454a86fd671ea5fea806"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
